#!/usr/bin/env python
# -*- mode: landisk-python; coding: utf-8; -*-
# vim:ts=4 sw=4 sts=4 ai si et sta

from __future__ import with_statement

from ..fileaccess import (MODE_READ, MODE_WRITE, ST_MODE_DIR, ST_MODE_FILE,
    DEFAULT_LOCALE, DEBUG)
from ionas.exception import *
from filelikeobj import FileLikeObj, FilePart

import os
import sys
import stat
import locale
import math
try:
    import email.utils as emailut
except:
    import email.Utils as emailut

from azure.storage import BlobService
from azure.http import HTTPError
import azure.storage.storageclient as sc

def _storage_error_handler(http_error):
    raise http_error

sc._storage_error_handler = _storage_error_handler

NO_CONTAINER_MSG = "The specified container does not exist."
NO_BLOB_MSG = "The specified blob does not exist."
INVALID_ACCESS_KEY_MSG = "Server failed to authenticate the request." + \
                         " Make sure the value of Authorization header is" + \
                         " formed correctly including the signature."
BODY_TOO_LARGE_MSG = "The request body is too large and exceeds " + \
                     "the maximum permissible limit."
NO_LEASE_ID_MSG = "There is currently a lease on the blob " + \
                  "and no lease ID was specified in the request."
ALREADY_LEASE_MSG = "There is already a lease present."
NO_LEASE_MSG = "There is currently no lease on the blob."
NOT_MATCH_LEASE_ID_MSG = "The lease ID specified did not match the lease ID for the blob."
INVALID_BLOCK_LIST_MSG = "The specified block list is invalid."
INVALID_BLOB_OR_BLOCK_MSG = "The specified blob or block content is invalid."
INVALID_ID_MSG = "The value for one of the HTTP headers is not in the correct format."
INVALID_BLOB_TYPE_MSG = "The blob type is invalid for this operation."

ERR_TABLE = {NO_CONTAINER_MSG: NoRootEntryError,
             NO_BLOB_MSG: NoEntryError,
             INVALID_ACCESS_KEY_MSG: InvalidPasswordError,
             BODY_TOO_LARGE_MSG: SizeTooLargeError,
             NO_LEASE_ID_MSG: FileLockError,
             NO_LEASE_MSG: FileLockError,
             ALREADY_LEASE_MSG: FileLockError,
             NOT_MATCH_LEASE_ID_MSG: FileLockError,
             INVALID_ID_MSG: FileLockError,
             INVALID_BLOCK_LIST_MSG: FileLockError,
             INVALID_BLOB_OR_BLOCK_MSG: FileLockError,
             INVALID_BLOB_TYPE_MSG: FileLockError}

PRIORITY_NONE = "none"
PRIORITY_FILE = "file"
PRIORITY_DIR = "dir"

UP_CHUNK_SIZE = 4 * 1024 * 1024
UP_SINGLE_CHUNK_SIZE = 64 * 1024 * 1024
MPUPLOAD_RETRY_NUM = 2

BLOB_SEP = "/"

ID_SEP = ","

PRE_ID_FMT = "%s" + ID_SEP + "%010d" + ID_SEP + "%010d" + ID_SEP + "%013d"

NUM_FMT = "%06d"

UNIQUE_INFO_IDX = 0
MTIME_IDX = 1
CTIME_IDX = 2
SIZE_IDX = 3
NUM_IDX = 4  


def azure_except_handler(exc_ins):
    msg = exc_ins.args[0]
    raise_exc = ERR_TABLE.get(msg, None)
    if raise_exc:
        raise raise_exc(exc_ins)
    raise exc_ins, None, sys.exc_info()[2]


def _upload_part(client, container, blob, fp, id, file_like):

    data = fp.read()

    def _exec_upload_part(retry_num=MPUPLOAD_RETRY_NUM):
        try:
            client.put_block(container, blob, data, id)
        except Exception, ins:
            if retry_num:
                _exec_upload_part(retry_num - 1)
            else:
                raise ins

    _exec_upload_part()


def _reset_blocks(client, container, blob):

    blists = client.get_block_list(container,
                                   blob,
                                   blocklisttype="committed")

    ids = [block.id
           for block
           in blists.committed_blocks]

    client.put_block_list(container, blob, ids, set="Committed")


def _resumable_upload(client, container, blob,
                      file_like, uploaded_part_list, pre_id):

    src_file_stat = file_like.get_stat()
    src_size = src_file_stat.st_size
    src_ctime = src_file_stat.st_ctime

    chunk_amount = int(math.ceil(src_size / float(UP_CHUNK_SIZE)))
    chunk_size = UP_CHUNK_SIZE

    uploaded_part_num_list = []
    for uploaded_part in uploaded_part_list:
        uploaded_part_num_list.append(int(uploaded_part.id.split(ID_SEP)[NUM_IDX]))

    ids = []

    for i in range(chunk_amount):
        part_num = i + 1

        id = pre_id + ID_SEP + NUM_FMT % part_num
        ids.append(id)

        if part_num in uploaded_part_num_list:
            continue

        offset = i * chunk_size
        remaining_bytes = src_size - offset
        bytes = min([chunk_size, remaining_bytes])

        fp = FilePart(file_like, offset, bytes)

        cur_file_stat = file_like.get_stat()
        cur_size = cur_file_stat.st_size
        cur_ctime = cur_file_stat.st_ctime

        try:
            if src_size != cur_size or src_ctime != cur_ctime:
                raise ModifiedInTransferring()

            _upload_part(client, container, blob, fp, id, file_like)
        except HTTPError, ins:
            if ins.args[0] == BODY_TOO_LARGE_MSG:
                # COMMENT
                # 100000 blocks over
                _reset_blocks(client, container, blob)
                raise FileLockError                

            azure_except_handler(ins)

    client.put_block_list(container, blob, ids, set="Uncommitted")


class AzureFileObj(FileLikeObj):

    def __init__(self, file, path, client, unique_info):

        self.sep = BLOB_SEP

        container_name, blob_path = path.strip(self.sep).split(self.sep, 1)

        self.container_name = container_name
        self.blob_path = blob_path
        self.client = client
        self.unique_info = unique_info

        FileLikeObj.__init__(self, file, path)

    def __len__(self):

        return self.file.size

    def tell(self):

        raise NotImplementedError

    def seek(self, offset, whence=os.SEEK_SET):

        raise NotImplementedError

    def get_path(self):

        raise NotImplementedError

    def read(self, size):

        raise NotImplementedError

    def get_pre_id(self, mtime, ctime, size):

        return PRE_ID_FMT % (self.unique_info, mtime, ctime, size)

    def resumable_upload(self, file_like):

        file_stat = file_like.get_stat()
        mtime = int(file_stat.st_mtime)
        ctime = int(file_stat.st_ctime)
        size = file_stat.st_size

        # 同size,同mtimeだが別内容である場合を考慮し、
        # ctimeの変化をチェック。
        # ctimeが同じで別内容であるケースは無視可能と判断。
        pre_id = self.get_pre_id(mtime, ctime, size)

        try:
            blists = self.client.get_block_list(self.container_name,
                                                self.blob_path,
                                                blocklisttype="all")

            if blists.committed_blocks:
                try:
                    srv_id_list = blists.committed_blocks[0].id.split(ID_SEP)

                    srv_unique_info = srv_id_list[UNIQUE_INFO_IDX]
                    srv_mtime = int(srv_id_list[MTIME_IDX])
                    srv_size = int(srv_id_list[SIZE_IDX])

                    cli_unique_info = self.unique_info
                    cli_mtime = mtime
                    cli_size = size

                    if (srv_unique_info == cli_unique_info and
                        srv_mtime == cli_mtime and
                        srv_size == cli_size):
                        return 

                except IndexError:
                    pass

            resumable_blocks = [block
                                for block
                                in blists.uncommitted_blocks
                                if block.id.startswith(pre_id)]

            _resumable_upload(self.client,
                              self.container_name,
                              self.blob_path,
                              file_like,
                              resumable_blocks,
                              pre_id)

        except HTTPError, ins:
            try:
                azure_except_handler(ins)
            except NoEntryError:
                _resumable_upload(self.client,
                                  self.container_name,
                                  self.blob_path,
                                  file_like,
                                  [],
                                  pre_id)

    def single_upload(self, file_like):

        self.client.put_block_blob_from_path(
            self.container_name,
            self.blob_path,
            file_like.get_path())

    def write_by_path(self, file_like):

        try:
            if file_like.get_size() >= UP_SINGLE_CHUNK_SIZE:
                self.resumable_upload(file_like)
            else:
                self.single_upload(file_like)

        except HTTPError, ins:
            azure_except_handler(ins)

    def read_by_path(self, file_like):

        try:
            propertie = self.client.get_blob_properties(self.container_name,
                                                        self.blob_path)
            size = propertie["content-length"]
            mtime = int(emailut.mktime_tz(
                emailut.parsedate_tz(
                    propertie["last-modified"])))

            self.client.get_blob_to_path(
                self.container_name,
                self.blob_path,
                file_like.get_path())

            cur_propertie = self.client.get_blob_properties(
                                self.container_name, self.blob_path)
            cur_size = cur_propertie["content-length"]
            cur_mtime = int(emailut.mktime_tz(
                emailut.parsedate_tz(
                    cur_propertie["last-modified"])))

            if size != cur_size or mtime != cur_mtime:
                raise ModifiedInTransferring()

        except HTTPError, ins:
            azure_except_handler(ins)

    def close(self):

        if hasattr(self.file, "close"):
            self.file.close()


class AzureAccess():

    def __init__(self, account_name, account_key, container="",
        protocol="https", encoding="", proxy_host=None, proxy_port=None,
        same_name_priority=PRIORITY_DIR, unique_info=""):

        self.sep = BLOB_SEP

        if encoding:
            self.encoding = encoding
        else:
            self.encoding = locale.getdefaultlocale()[1]
            if not self.encoding:
                self.encoding = DEFAULT_LOCALE

        self.container = container
        self.same_name_priority = same_name_priority
        self.unique_info = unique_info

        try:
            self.client = BlobService(account_name, account_key, protocol)
            if proxy_host and proxy_port:
                self.client.set_proxy(proxy_host, proxy_port)

        except HTTPError, ins:
            azure_except_handler(ins)

    def listdir(self, path):
        raise NotImplementedError

    def isdir(self, entry):
        raise NotImplementedError

    def open(self, path, mode):
        try:
            return AzureFileObj(None, path, self.client, self.unique_info)

        except HTTPError, ins:
            azure_except_handler(ins)

    def __get_time(self, blob):
        return emailut.mktime_tz(
               emailut.parsedate_tz(
               blob["last-modified"]))

    def __get_stat_exc_handle(self, container, blob_path, do_handle=True):
        try:
            return self.client.get_blob_properties(container, blob_path)
        except HTTPError, ins:
            try:
                azure_except_handler(ins)
            except NoEntryError, ins:
                if do_handle:
                    return None
                else:
                    raise ins

    def __get_stat_priority_dir(self, container, blob_path):
        blob = self.__get_stat_exc_handle(container,
                                          blob_path + self.sep)
        if not blob:
            blob = self.__get_stat_exc_handle(container,
                                              blob_path,
                                              False)
            """ This Is File. """
            st_mode = ST_MODE_FILE
        else:
            st_mode = ST_MODE_DIR

        st_mtime = self.__get_time(blob)
        st_size = int(blob["content-length"])

        return (st_mode, st_mtime, st_size)

    def __get_stat_priority_file(self, container, blob_path):
        blob = self.__get_stat_exc_handle(container,
                                          blob_path)
        if not blob:
            blob = self.__get_stat_exc_handle(container,
                                              blob_path + self.sep,
                                              False)
            """ This Is Dir. """
            st_mode = ST_MODE_DIR
            st_size = None
        else:
            st_mode = ST_MODE_FILE
            st_size = int(blob["content-length"])

        st_mtime = self.__get_time(blob)

        return (st_mode, st_mtime, st_size)

    def __get_stat(self, container, blob_path):
        if self.same_name_priority == PRIORITY_FILE:
            return self.__get_stat_priority_file(container, blob_path)
        if self.same_name_priority == PRIORITY_DIR:
            return self.__get_stat_priority_dir(container, blob_path)
        else:
            # COMMENT 他にパターンあれば実装
            return self.__get_stat_priority_dir(container, blob_path)

    def __is_block_blob(self, container, blob_path):
        prop = self.client.get_blob_properties(container, blob_path)
        if prop["x-ms-blob-type"] != "BlockBlob":
            return False
        return True

    def stat(self, path):
        try:
            path_list = path.strip(self.sep).split(self.sep, 1)
            container = path_list[0]

            if len(path_list) == 2:
                blob_path = path_list[1]
                st_mode, st_mtime, st_size = self.__get_stat(
                    container, blob_path)
            elif len(path_list) == 1:
                # COMMENT containerはDIR扱い
                st_mode = ST_MODE_DIR
                st_mtime = None
                st_size = 0

            return {
                stat.ST_MODE: st_mode,
                stat.ST_MTIME: st_mtime,
                stat.ST_SIZE: st_size}

        except HTTPError, ins:
            azure_except_handler(ins)

    # COMMENT nasdsyncはupload,download両方共localをutimeしている。
    # dropbox側はutimeできない。
    # 時刻を基準にファイル更新判断しているので、
    # local側を更新することにより時刻一致させている。
    #def utime(self, path, mtime):
    #    pass

    def remove(self, path):
        try:
            container, blob_path = path.strip(self.sep).split(self.sep, 1)

            if not self.__is_block_blob(container, blob_path):
                return

            # COMMENT blob_pathもある前提
            self.client.delete_blob(container, blob_path)

        except HTTPError, ins:
            azure_except_handler(ins)

    def rmdir(self, path):
        try:
            path_list = path.strip(self.sep).\
                             rstrip(self.sep).\
                             split(self.sep, 1)
            container = path_list[0]
            if len(path_list) == 2:
                blob_path = path_list[1]
                blob_list = self.client.list_blobs(container,
                                                   blob_path + self.sep)
                for blob in blob_list:
                    if not self.__is_block_blob(container, blob.name):
                        return
                    self.client.delete_blob(container, blob.name)
            elif len(path_list) == 1:
                self.client.delete_container(container)

        except HTTPError, ins:
            azure_except_handler(ins)

    def mkdir(self, path):
        try:
            path_list = path.strip(self.sep).\
                             rstrip(self.sep).\
                             split(self.sep, 1)
            container = path_list[0]

            if len(path_list) == 1:
                self.client.create_container(container)

            if len(path_list) == 2:
                blob_path = path_list[1]
                self.client.put_block_blob_from_bytes(container,
                                                      blob_path + self.sep,
                                                      "")
        except HTTPError, ins:
            azure_except_handler(ins)

    def get_list(self, container="", marker=None):
        try:
            if not container:
                return self.client.list_blobs(self.container, marker=marker)
            else:
                return self.client.list_blobs(container, marker=marker)

        except HTTPError, ins:
            azure_except_handler(ins)
