#!/usr/bin/env python
# -*- mode: landisk-python; coding: utf-8; -*-
# vim:ts=4 sw=4 sts=4 ai si et sta

from __future__ import with_statement

import os
import sys
import errno
import socket
import time
import calendar
import re
import stat

from ionas.exception import *
from ionas.fileaccess import (
    AmazonS3Access,
    amazons3_except_handler,
    PRIORITY_NONE,
    PRIORITY_FILE,
    PRIORITY_DIR,
    MODE_WRITE)
from ionas.fileaccess.amazons3access import (
    multipart_upload_lister, get_part_list,
    UP_MIN_CHUNK_SIZE)
from basefilesync import(
    DEBUG,
    SrcFull, DstFull,
    DIRS_NAME,
    FILES_NAME,
    MTIME_NAME,
    SIZE_NAME,
    CHILDREN_NAME,
    STATE_NAME,
    ERRINFO_NAME,
    STATE_NEW,
    STATE_DEL,
    STATE_SAME,
    ERR_STATE_PREFIX,
    NG_LOG,
    GET_TREE_LOG,
    GET_DELTA_TREE_LOG,
    ERROR_LOG_LV,
    get_new_tree,
    MODE_CH_FILE,
    MODE_CH_DIR)

DEFAULT_MAX_FILE_SIZE = 5 * 1024 * 1024 * 1024

LINE_FMT = "%s,%s,%s,%s,%s\n"

NOTHING = None

FNAME_IDX = -5
ID_IDX = -4
MTIME_IDX = -3
CTIME_IDX = -2
SIZE_IDX = -1

INT_NONE = -1

GET_TREE_RETRY_NUM = 2


class AmazonS3FileTree(SrcFull, DstFull):

    def __init__(self, key, secret, bucket,
        log_callback=None, ignored_list=[], encoding="",
        for_sync=True, is_secure=True, rrs=False,
        proxy_host=None, proxy_port=None,
        validate=False, same_name_priority=PRIORITY_DIR,
        host=None, port=None,
        max_file_size=None, mpupload=False,
        uploading_path="", uploaded_path=""):

        self.amazons3_access = AmazonS3Access(
            key, secret, bucket, encoding,
            is_secure, rrs, proxy_host, proxy_port,
            validate, same_name_priority, host, port, mpupload)

        SrcFull.__init__(self, bucket,
                         ignored_list, log_callback)
        DstFull.__init__(self, bucket,
                         log_callback, for_sync=for_sync, err_del=False)

        if not max_file_size:
            self.MAX_FILE_SIZE = DEFAULT_MAX_FILE_SIZE
        else:
            self.MAX_FILE_SIZE = max_file_size

        self.sep = self.amazons3_access.sep
        self.encoding = self.amazons3_access.encoding

        # COMMENT Amazon S3は完全同名のfile,dirを作成可能
        # どちらを優先して取得するかのフラグ
        self.same_name_priority = same_name_priority

        # COMMENT reset_proxy_infoのため
        self.key = key
        self.secret = secret
        self.bucket = bucket
        self.is_secure = is_secure
        self.rrs = rrs
        self.proxy_host = proxy_host
        self.proxy_port = proxy_port
        self.host = host
        self.port = port
        self.mpupload = mpupload

        self.uploading_path = uploading_path
        self.uploaded_path = uploaded_path

        if self.uploading_path:
            self.reset_cli_side_mps()
            self.reset_srv_side_mps()
        else:
            self.reset_cli_side_mps(False)
            self.reset_srv_side_mps()

    def listdir(self, path):
        return self.amazons3_access.listdir(path)

    def delete_all_mps(self):

        ing = self.uploading_path
        ed = self.uploaded_path

        if os.path.exists(ing):
            os.unlink(ing)
        if os.path.exists(ed):
            os.unlink(ed)

        for mp in multipart_upload_lister(self.amazons3_access.bucket):
            mp.cancel_upload()

    def delete_disuse_mps(self):

        ing = self.uploading_path
        ed = self.uploaded_path

        def del_key(fname):
            try:
                del self.cli_side_mps[fname]
            except KeyError:
                pass

        def modify_file(path, is_comp=False):

            if not os.path.exists(path):
                return

            mp_list = []
            with open(path) as rf:
                for line in rf.readlines():
                    try:
                        mps_info_list = line.rstrip().split(",")

                        fname = ",".join(mps_info_list[:FNAME_IDX + 1])
                        id = mps_info_list[ID_IDX]

                        src = self.src
                        relpath = re.sub(r"^%s" % re.escape(src.root + src.sep), "", fname)

                        if not is_comp and os.path.exists(fname):
                            fsize = os.stat(fname)[stat.ST_SIZE]
                            if fsize < UP_MIN_CHUNK_SIZE:
                                if id:
                                    self.cancel_halfway_mpupload(id)
                                elif fname:
                                    self.cancel_halfway_mpupload(path=relpath)
                            else:
                                mp_list.append(line)
                        else:
                            del_key(fname)
                    except:
                        pass

            with open(path, "w") as wf:
                for line in mp_list:
                    wf.write(line)

        modify_file(ing)
        modify_file(ed, True)

    def reset_cli_side_mps(self, do=True):

        cli_side_mps = {}

        if not do:
            return

        ing = self.uploading_path
        ed = self.uploaded_path

        def get_int(str_val):
            if str_val.isdigit():
                return int(str_val)
            return INT_NONE

        def set_mps(path, is_comp=False):

            if not os.path.exists(path):
                return

            with open(path) as rf:
                for line in rf.readlines():
                    try:
                        mps_info_list = line.rstrip().split(",")

                        fname = ",".join(mps_info_list[:FNAME_IDX + 1])
                        id = mps_info_list[ID_IDX]
                        mtime = get_int(mps_info_list[MTIME_IDX])
                        ctime = get_int(mps_info_list[CTIME_IDX])
                        size = get_int(mps_info_list[SIZE_IDX])

                        cli_side_mps.update({fname: {"id": id,
                                                     "mtime": mtime,
                                                     "ctime": ctime,
                                                     "size":  size,
                                                     "is_comp": is_comp}})
                    except:
                        pass

        set_mps(ing)
        set_mps(ed, True)

        self.cli_side_mps = cli_side_mps

    def reset_srv_side_mps(self):

        self.srv_side_mps = NOTHING

    def _get_srv_side_mps(self):

        if self.srv_side_mps == NOTHING:
            self.srv_side_mps = [
                mp
                for mp
                in multipart_upload_lister(self.amazons3_access.bucket)]

        return self.srv_side_mps

    def _get_src_relpath(self, abspath):
        src = self.src
        return re.sub(r"^%s" % re.escape(src.root + src.sep), "", abspath)

    def _get_mp(self, key_path, rrs, file_like):

        path = file_like.get_path()

        cli_cur_stat = self.src.stat(path, ctime=False)
        cli_cur_size = cli_cur_stat[stat.ST_SIZE]
        cli_cur_mtime = cli_cur_stat[stat.ST_MTIME]
        cli_cur_stat = self.src.stat(path, ctime=True)
        cli_cur_ctime = cli_cur_stat[stat.ST_MTIME]

        cli_last_stat = self.cli_side_mps.get(path, {})
        cli_last_id = ""
        cli_last_is_comp = False
        cli_last_size = INT_NONE
        cli_last_mtime = INT_NONE
        cli_last_ctime = INT_NONE

        if cli_last_stat:
            cli_last_id = cli_last_stat["id"]
            cli_last_is_comp = cli_last_stat["is_comp"]
            cli_last_size = cli_last_stat["size"]
            cli_last_mtime = cli_last_stat["mtime"]
            cli_last_ctime = cli_last_stat["ctime"]

        try:
            srv_path = self.sep.join([self.root] + [key_path])
            srv_cur_stat = self.stat(srv_path)
            srv_cur_size = srv_cur_stat[stat.ST_SIZE]
            srv_cur_mtime = srv_cur_stat[stat.ST_MTIME]
        except NoEntryError:
            pass
        else:
            if cli_cur_size == srv_cur_size and cli_cur_mtime == srv_cur_mtime:
                # uploadリトライの合間にdownloadされた場合
                if cli_last_id:
                    self.cancel_halfway_mpupload(cli_last_id)
                self._delete_mp(path)
                return (None, [])

        def set_pre_mp():
            # initiate前にupload元ファイルの情報を残す
            cur_path = file_like.get_path()

            last_path = ""
            last_id = ""
            for mp_path, val in self.cli_side_mps.iteritems():
                if not val["is_comp"]:
                    last_path = mp_path
                    last_id = val["id"]
                    break

            relpath = self._get_src_relpath(last_path)

            if last_path and not last_id:
                self.cancel_halfway_mpupload(path=relpath)
            elif cur_path != last_path:
                if last_id:
                    self.cancel_halfway_mpupload(id=last_id)
                elif last_path:
                    self.cancel_halfway_mpupload(path=relpath)
                self._delete_mp(last_path)

            line = LINE_FMT % (cur_path, "", "", "", "")

            # 確実にHDDへflushしてからinitiate
            with open(self.uploading_path, "w") as wf:
                wf.write(line)
                wf.flush()
                os.fsync(wf.fileno())
            os.chmod(path, MODE_CH_FILE)

        def get_initiate():
            set_pre_mp()
            self._pre_upload(file_like)
            return (self.amazons3_access.bucket.initiate_multipart_upload(
                key_path, reduced_redundancy=rrs), [])

        if not cli_last_stat:
            return get_initiate()

        # 同size,同mtimeだが別内容である場合を考慮し、
        # ctimeの変化をチェック。
        # ctimeが同じで別内容であるケースは無視可能。
        if cli_last_size != cli_cur_size or cli_last_ctime != cli_cur_ctime:
            if cli_last_id:
                self.cancel_halfway_mpupload(cli_last_id)
            else:
                relpath = self._get_src_relpath(path)
                self.cancel_halfway_mpupload(path=relpath)
            return get_initiate()

        if cli_last_is_comp:
            return (None, [])

        for mp in self._get_srv_side_mps():
            if cli_last_stat.get("id") == mp.id:
                return (mp, get_part_list(mp))

        return get_initiate()

    def _delete_mp(self, del_fname):

        ing = self.uploading_path
        ed = self.uploaded_path

        try:
            del self.cli_side_mps[del_fname]
        except KeyError:
            pass

        def modify_file(path):
            if not os.path.exists(path):
                return

            mp_list = []
            with open(path) as rf:
                for line in rf.readlines():
                    try:
                        mps_info_list = line.rstrip().split(",")

                        fname = ",".join(mps_info_list[:FNAME_IDX + 1])

                        if del_fname != fname:
                            mp_list.append(line)
                    except:
                        pass

            with open(path, "w") as wf:
                for line in mp_list:
                    wf.write(line)

        modify_file(ing)
        modify_file(ed)

    def _set_mp(self, mp, file_like):

        path = file_like.get_path()

        cur_stat = self.src.stat(path, ctime=False)
        cur_size = cur_stat[stat.ST_SIZE]
        cur_mtime = cur_stat[stat.ST_MTIME]

        cur_stat = self.src.stat(path, ctime=True)
        cur_ctime = cur_stat[stat.ST_MTIME]

        last_stat = self.cli_side_mps.get(path)
        if last_stat:
            if (last_stat["id"] == mp.id and
                last_stat["size"] == cur_size and
                last_stat["mtime"] == cur_mtime):
                return
            else:
                self._delete_mp(path)

        line = LINE_FMT % (path,
                           str(mp.id),
                           str(cur_mtime),
                           str(cur_ctime),
                           str(cur_size))

        with open(self.uploading_path, "w") as wf:
            wf.write(line)
        os.chmod(self.uploading_path, MODE_CH_FILE)

    def _pre_upload(self, file_like):

        src = self.src

        src_abspath = file_like.get_path()
        src_relpath = re.sub(r"^%s" % re.escape(src.root + src.sep),
                             "",
                             src_abspath).split(src.sep)
        self.src.chmod(src_abspath, MODE_CH_FILE)
        src_file_stat = src.stat(src_abspath)
        src_mtime = src_file_stat[stat.ST_MTIME]
        src.update_delta_info(src_relpath, mtime=src_mtime)

    def _post_upload(self, file_like):

        ing = self.uploading_path
        ed = self.uploaded_path
        ed_dir = os.path.dirname(ed)

        if not os.path.exists(ing) or not ed:
            return

        if not os.path.exists(ed_dir):
            os.makedirs(ed_dir)
            os.chmod(ed_dir, MODE_CH_DIR)

        with open(ing) as rf:
            buf = rf.read()

        try:
            if buf:

                mp_info_list = buf.rstrip().split(",")

                fname = ",".join(mp_info_list[:FNAME_IDX + 1])
                mtime = mp_info_list[MTIME_IDX]
                ctime = mp_info_list[CTIME_IDX]
                size = mp_info_list[SIZE_IDX]

                # idは不要なので,disk容量節約のため除外
                line = LINE_FMT % (fname, "", mtime, ctime, size)

                with open(ed, "a") as wf:
                    wf.write(line)
                os.chmod(ed, MODE_CH_FILE)

        except (IOError, OSError), exc_ins:
            if exc_ins.errno != errno.ENOSPC and exc_ins.errno != errno.EDQUOT:
                raise

        os.unlink(ing)

    def _post_cancel(self, file_like):
        self._delete_mp(file_like.get_path())

    def open(self, path, mode):
        if self.for_sync and mode == MODE_WRITE:

            """
            s3側ファイルのmodify timeは
            upload開始時点の時刻となるが、
            botoのset_contents_from_fileメソッドでは
            その引数にmd5を渡さない場合は
            そのメソッドの内部で計算してから
            upload開始するので、
            そのメソッド実行前にlocal側ファイルの
            ctimeを更新しても
            md5計算時間分だけずれてしまう。
            引数にmd5を渡せばそのmd5を使うので
            AmazonS3Accessにて
            md5計算->local側ファイルをctime更新->upload
            とするためここでcallback関数を用意し渡す。
            """

            upload_cbs = {"get_mp": self._get_mp,
                          "set_mp": self._set_mp,
                          "pre_upload": self._pre_upload,
                          "post_upload": self._post_upload,
                          "post_cancel": self._post_cancel}
        else:
            upload_cbs = {}

        return self.amazons3_access.open(path, mode, upload_cbs)

    def mkdir(self, path):
        self.amazons3_access.mkdir(path)

    def stat(self, path):
        return self.amazons3_access.stat(path)

    # COMMENT いずれAPIが対応するかも
    #def utime(self, path, mtime):
    #    self.amazons3_access.utime(path, mtime)

    def remove(self, path):
        self.amazons3_access.remove(path)

    def rmdir(self, path):
        self.amazons3_access.rmdir(path)

    def __add_file(self, tree, name, size, mtime):
        if self.same_name_priority == PRIORITY_DIR:
            try:
                tree[DIRS_NAME][name]
            except KeyError:
                tree[FILES_NAME][name] = {
                    MTIME_NAME: mtime,
                    SIZE_NAME: size}
            return
        if self.same_name_priority == PRIORITY_FILE:
            try:
                del tree[DIRS_NAME][name]
            except:
                pass
            finally:
                tree[FILES_NAME][name] = {
                    MTIME_NAME: mtime,
                    SIZE_NAME: size}
            return
        if self.same_name_priority == PRIORITY_NONE:
            tree[FILES_NAME][name] = {
                    MTIME_NAME: mtime,
                    SIZE_NAME: size}
            return

    def __add_dir(self, tree, name, mtime):
        if tree[DIRS_NAME].has_key(name):
            return

        if self.same_name_priority == PRIORITY_DIR:
            try:
                del tree[FILES_NAME][name]
            except:
                pass
            finally:
                tree[DIRS_NAME][name] = {
                    MTIME_NAME: mtime,
                    CHILDREN_NAME: {DIRS_NAME: {}, FILES_NAME: {}}}
            return
        if self.same_name_priority == PRIORITY_FILE:
            try:
                tree[FILES_NAME][name]
            except KeyError:
                tree[DIRS_NAME][name] = {
                    MTIME_NAME: mtime,
                    CHILDREN_NAME: {DIRS_NAME: {}, FILES_NAME: {}}}
            return
        if self.same_name_priority == PRIORITY_NONE:
            tree[DIRS_NAME][name] = {
                MTIME_NAME: mtime,
                CHILDREN_NAME: {DIRS_NAME: {}, FILES_NAME: {}}}

    def __get_tree(self, key, tree, prefix=""):
        suffix = re.sub(r"^%s" % re.escape(prefix) + self.sep,
            "", key.name.encode(self.encoding))
        path_list = suffix.rstrip(self.sep).split(self.sep)
        mtime = calendar.timegm(time.strptime(
            str(key.last_modified).split(".")[0], "%Y-%m-%dT%H:%M:%S"))
        if len(path_list) == 1:
            if not suffix.endswith(self.sep):
                """ This is File. """
                self.__add_file(tree, path_list[0], int(key.size), mtime)
            else:
                """ This is Directory. """
                self.__add_dir(tree, path_list[0], mtime)
        else:
            try:
                children = tree[DIRS_NAME][path_list[0]][CHILDREN_NAME]
            except KeyError:
                self.__add_dir(tree, path_list[0], mtime)
                try:
                    children = tree[DIRS_NAME][path_list[0]][CHILDREN_NAME]
                except KeyError:
                    return
            self.__get_tree(
                key,
                children,
                str(prefix + self.sep + path_list[0]).lstrip(self.sep))

### COMMENT 差分ツリー取得処理は以下。
### 非コメント処理がリストで
### メモリ圧迫しすぎるならこちらのコメント処理か。
### 処理時間は長くなる
#    def __compair(self, key, obj):
#        if (key.last_modified != obj[MTIME_NAME] or
#            key.size != obj[SIZE_NAME]):
#            obj[MTIME_NAME] = key.last_modified
#            obj[SIZE_NAME] = key.size
#            obj[STATE_NAME] = STATE_NEW
#            return True
#        else:
#            obj[STATE_NAME] = STATE_SAME
#            return false
#
#    def __set_update(self, key, tree, prefix=""):
#        is_updated = False
#
#        suffix = re.sub(r"^%s" % prefix + self.sep, "", key.name)
#        path_list = suffix.split(self.sep)
#        if len(path_list) == 1:
#            if path_list[0]:
#                """ This is File. """
#                if not path_list[0] in tree[FILES_NAME]:
#                    tree[FILES_NAME][path_list[0]] = {
#                        MTIME_NAME: int(key.last_modified),
#                        SIZE_NAME: int(key.size),
#                        STATE_NAME: STATE_NEW}
#                    is_updated = True
#                else:
#                    is_updated = self.__compair(
#                        key, tree[FILES_NAME][path_list[0]])
#            else:
#                """ This is Directory. """
#                if not path_list[0] in tree[DIRS_NAME]:
#                    tree[DIRS_NAME][path_list[0]] = {
#                        CHILDREN_NAME: {DIRS_NAME: {}, FILES_NAME: {}},
#                        STATE_NAME: STATE_NEW}
#                    is_updated = True
#                else:
#                    tree[DIRS_NAME][name][STATE_NAME] = STATE_SAME
#        else:
#            try:
#                children = tree[DIRES_NAME][path_list[0]][CHILDREN_NAME]
#            except KeyError:
#                # COMMENT amazonのlistがよい
#                # 形ならこちらへはこない
#                children = tree[DIRS_NAME][path_list[0]] = {
#                    CHILDREN_NAME: {DIRS_NAME: {}, FILES_NAME: {}},
#                    STATE_NAME: STATE_NEW}
#                is_updated = True
#            is_updated = self.__set_update(
#                key,
#                children,
#                self.sep.join(path_list[1:]))
#        return is_updated
#
#    def _set_update(self, tree, list_iter):
#        is_updated = False
#        for key in list_iter:
#            if self.__set_update(key, tree):
#                is_updated = True
#        return is_updated
#
#    def _set_delete(self, tree, list_iter, prefix=""):
#        is_updated = False
#        for name in tree[FILES_NAME].keys():
#            for key in list_iter:
#                suffix = re.sub(r"^%s" % prefix + self.sep, "", key.name)
#                path_list = suffix.split(self.sep)
#                if len(path_list) == 1:
#                    """ This is File. """
#                    if path_list[0] == name:
#
#            if self.__set_delete(key, tree):
#                is_updated = True
#        return is_updated

    def __set_update(self, root_tree, update_tree):
        is_updated = False
        for update_name in update_tree[FILES_NAME]:
            if update_name in root_tree[FILES_NAME].keys():
                update_info = update_tree[FILES_NAME][update_name]
                root_info = root_tree[FILES_NAME][update_name]
                if root_info[STATE_NAME].startswith(ERR_STATE_PREFIX):
                    root_info[STATE_NAME] = re.sub(
                        "^" + ERR_STATE_PREFIX, "", root_info[STATE_NAME])
                    is_updated = True

                elif root_info[STATE_NAME] == STATE_DEL:
                    root_info[STATE_NAME] = STATE_SAME

                elif (update_info[MTIME_NAME] != root_info[MTIME_NAME] or
                    update_info[SIZE_NAME] != root_info[SIZE_NAME]):
                    root_info[MTIME_NAME] = update_info[MTIME_NAME]
                    root_info[SIZE_NAME] = update_info[SIZE_NAME]
                    root_info[STATE_NAME] = STATE_NEW
                    is_updated = True

            else:
                is_updated = True
                root_tree[FILES_NAME][update_name] = {
                    MTIME_NAME: update_tree[
                        FILES_NAME][update_name][MTIME_NAME],
                    SIZE_NAME: update_tree[
                        FILES_NAME][update_name][SIZE_NAME],
                    STATE_NAME: STATE_NEW}

        for update_dir in update_tree[DIRS_NAME]:
            if update_dir in root_tree[DIRS_NAME].keys():
                update_info = update_tree[DIRS_NAME][update_dir]
                root_info = root_tree[DIRS_NAME][update_dir]

                if root_info[STATE_NAME] == STATE_DEL:
                    root_info[STATE_NAME] = STATE_SAME

                elif root_info[
                    STATE_NAME].startswith(ERR_STATE_PREFIX):
                    root_info[STATE_NAME] = re.sub(
                        "^" + ERR_STATE_PREFIX, "", root_info[STATE_NAME])
                    is_updated = True

                else:
                    # COMMENT exact_first時に
                    # 両方にほぼ同時刻のdir"A"があり、
                    # その下のfile,dirに差異がある場合に、
                    # get_sync_dup_tree_distrust_new()では
                    # dir"A"はsameになるが、
                    # その下はnewになり、dst.update()内では
                    # dir"A"はsameなので
                    # update_delta_infoされず、
                    # その下のfile,dirの転送の際に
                    # update_delta_infoされるので、そのとき
                    # update_delta_infoの"mtimeのない
                    # dirエントリができる"ルーチンを
                    # 通ることへの対処。
                    # mtimeがないと、
                    # 後のget_sync_dup_tree_distrust_newで
                    # KeyErrorになる
                    try:
                        root_info[MTIME_NAME]
                    except KeyError:
                        root_info[MTIME_NAME] = update_info[MTIME_NAME]
                        root_info[STATE_NAME] = STATE_SAME

            else:
                is_updated = True
                root_tree[DIRS_NAME][update_dir] = {
                    MTIME_NAME: update_tree[DIRS_NAME][update_dir][MTIME_NAME],
                    STATE_NAME: STATE_NEW,
                    CHILDREN_NAME: {DIRS_NAME: {}, FILES_NAME: {}}}
            if self.__set_update(
                root_tree[DIRS_NAME][update_dir][CHILDREN_NAME],
                update_tree[DIRS_NAME][update_dir][CHILDREN_NAME]):
                is_updated = True
        return is_updated

    def __set_delete(self, root_tree, update_tree):
        is_updated = False
        for file in root_tree[FILES_NAME]:
            if (not file in update_tree[FILES_NAME].keys() and
                root_tree[FILES_NAME][file][STATE_NAME] != STATE_DEL):
                is_updated = True
                root_tree[FILES_NAME][file][STATE_NAME] = STATE_DEL

        for dir in root_tree[DIRS_NAME]:
            if not dir in update_tree[DIRS_NAME].keys():
                if root_tree[DIRS_NAME][dir][STATE_NAME] != STATE_DEL:
                    is_updated = True
                    root_tree[DIRS_NAME][dir][STATE_NAME] = STATE_DEL
            else:
                if self.__set_delete(
                    root_tree[DIRS_NAME][dir][CHILDREN_NAME],
                    update_tree[DIRS_NAME][dir][CHILDREN_NAME]):
                    is_updated = True
        return is_updated

    def __get_delta_tree(self, root_tree, update_tree):
        is_updated = False
        if self.__set_update(root_tree, update_tree):
            is_updated = True
        if self.__set_delete(root_tree, update_tree):
            is_updated = True
        return (is_updated, root_tree)

    def get_tree(self):
        """ Over ride. """
        try:
            # 多数(10万)ファイルのS3同期で、
            # get_tree時にsocket.errorの
            # Connection reset by peerが
            # 多発するケースに対処

            def _get_tree():
                tree = {DIRS_NAME: {}, FILES_NAME: {}}
                for key in self.amazons3_access.get_list(self.root):
                    self.__get_tree(key, tree)
                return tree

            def _is_retry_exc(ins):
                if not isinstance(ins, socket.error):
                    return False
                if ins.args[0] != errno.ECONNRESET:
                    return False
                return True

            for num in reversed(range(GET_TREE_RETRY_NUM)):
                try:
                    return _get_tree()
                except Exception, ins:
                    tb_info = sys.exc_info()[2]
                    if not _is_retry_exc(ins) or num == 0:
                        raise ins, None, tb_info

        except Exception, ins:
            self.logging(ERROR_LOG_LV, GET_TREE_LOG + " " + NG_LOG,
                src=self.root, trace=True)

            # get_listは戻り値をイテレーションしたときに
            # 例外発生するのでここでhandle
            amazons3_except_handler(ins)

    def get_delta_tree(self):
        """ Over ride. """
        # COMMENT 戻り値:(更新有無, 差分情報ツリー)
        try:
            if not self.tree:
                self.tree = get_new_tree(self.get_tree())
                return (True, self.tree)
            else:
                update_tree = self.get_tree()
                is_updated, self.tree = self.__get_delta_tree(
                    self.tree, update_tree)
                return (is_updated, self.tree)
        except Exception, ins:
            self.logging(ERROR_LOG_LV, GET_DELTA_TREE_LOG + " " + NG_LOG,
                src=self.root, trace=True)

            # get_listは戻り値をイテレーションしたときに
            # 例外発生するのでここでhandle
            amazons3_except_handler(ins)

    def reset_proxy_info(self, proxy_host, proxy_port):
        self.amazons3_access = AmazonS3Access(
            self.key, self.secret, self.bucket, self.encoding,
            self.is_secure, self.rrs,
            proxy_host, proxy_port, host=self.host,
            port=self.port, mpupload=self.mpupload)

    def cancel_halfway_mpupload(self, id="", path=""):
        self.amazons3_access.cancel_halfway_mpupload(id, path)

    def resume_halfway_mpupload(self, id, file_like):

        upload_cbs = {"post_upload": self._post_upload,
                      "post_cancel": self._post_cancel}
        self.amazons3_access.resume_halfway_mpupload(id, file_like, upload_cbs)

    def pre_file_transfer(self, file_relpath, file_info):
        if self.MAX_FILE_SIZE:
            if file_info[SIZE_NAME] >= self.MAX_FILE_SIZE:
                raise SizeTooLargeError

    def pre_dir_create(self, dir_relpath, dir_info):
        if self.for_sync:
            self.src.chmod(self.src.sep.join(
                [self.src.root] + dir_relpath), MODE_CH_DIR)
            src_dir_stat = self.src.stat(
                self.src.sep.join([self.src.root] + dir_relpath))
            src_mtime = src_dir_stat[stat.ST_MTIME]
            self.src.update_delta_info(dir_relpath, mtime=src_mtime)

    def post_file_transfer(self, file_relpath, file_info):
        # COMMENT dropboxのようにdst側の
        # utimeができない場合の処理。将来不要になるかも
        # 現時点ではdropbox -> dropboxは
        # 時刻同期不可ということ
        # データコピー時は、
        # サーバ側とNAS側の時刻揃える処理不要なので
        # for_syncフラグで制御

        if self.for_sync:
            """
            新fileをupload->すぐにs3側上でそのファイルを削除
            といった操作時に、次のdownload時に
            そのファイルが"元からs3上にない"のか
            "s3上から削除された"のか
            ということを認識するために
            dst.update_delta_infoは必要
            """
            dst_file_stat = self.stat(self.sep.join(
                [self.root] + file_relpath))
            dst_mtime = dst_file_stat[stat.ST_MTIME]
            dst_size = dst_file_stat[stat.ST_SIZE]
            self.update_delta_info(file_relpath, mtime=dst_mtime,
                                   size=dst_size, state=STATE_SAME,
                                   delete_keys=[ERRINFO_NAME])

            self.src.update_delta_info(file_relpath,
                                       state=STATE_SAME,
                                       delete_keys=[ERRINFO_NAME])

    def post_dir_create(self, dir_relpath, dir_info):
        if self.for_sync:
            dst_dir_stat = self.stat(self.sep.join([self.root] + dir_relpath))
            dst_mtime = dst_dir_stat[stat.ST_MTIME]
            self.update_delta_info(dir_relpath, mtime=dst_mtime,
                                   state=STATE_SAME, is_dir=True,
                                   delete_keys=[ERRINFO_NAME])

            self.src.update_delta_info(dir_relpath,
                                       state=STATE_SAME,
                                       delete_keys=[ERRINFO_NAME])

    def post_file_delete(self, file_relpath, file_info):
        if self.for_sync:
            self.update_delta_info(file_relpath, delete=True)

    def post_dir_delete(self, dir_relpath, dir_info):
        if self.for_sync:
            self.update_delta_info(dir_relpath, delete=True)
